<!DOCTYPE html>
<html lang="en">
<head>
          <title>CMPUT 402 - Group Assignment 2: Testing</title>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="Software Quality" />
        <link href="https://cmput402.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="CMPUT 402 Full Atom Feed" />
        <link href="https://cmput402.github.io/feeds/group.atom.xml" type="application/atom+xml" rel="alternate" title="CMPUT 402 Categories Atom Feed" />

  <link rel="icon" href="https://cmput402.github.io/theme/favicon.png" />
  <link rel="stylesheet" type="text/css" href="https://cmput402.github.io/theme/style.css" />
  <link rel="stylesheet" type="text/css" href="https://cmput402.github.io/theme/402.css" />




    <meta name="tags" content="labs" />
    <meta name="tags" content="policy" />
    <meta name="tags" content="grading" />

</head>

<body>
        <header>
              <hgroup><h1><a href="https://cmput402.github.io/">CMPUT 402</a></h1><p>Software Quality</p></hgroup>
        <nav><ul>
            <li><a href="/general/outline.html">Outline</a></li>
            <li><a href="https://eclass.srv.ualberta.ca/course/view.php?id=95226">eClass</a></li>
            <li><a href="/general/schedule.html">Schedule</a></li>
            <li><a href="/general/labs.html">Labs</a></li>
            <li><a href="/general/project.html">Project</a></li>
            <li><a href="/general/resources.html">Resources</a></li>
            <li><a href="/general/help.html">Help</a></li>
        </ul></nav>
        </header>
        <main>
<article>
  <header>
    <h2>
      <a href="https://cmput402.github.io/group/testing.html" rel="bookmark"
         title="Permalink to Group Assignment 2: Testing">Group Assignment 2: Testing</a></h2>
 
  </header>
  <div class="toc">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#part-1-improve-test-suite">Part 1: Improve Test Suite</a><ul>
<li><a href="#acceptance-criteria-for-part-1">Acceptance criteria for Part 1</a></li>
</ul>
</li>
<li><a href="#part-2-implementation-and-verification-of-a-smart-door-lock">Part 2: Implementation and Verification of a Smart Door Lock</a><ul>
<li><a href="#acceptance-criteria-for-part-2">Acceptance criteria for Part 2</a></li>
</ul>
</li>
<li><a href="#report-for-parts-1-2">Report for Parts 1 &amp; 2</a></li>
<li><a href="#grading-summary">Grading Summary</a></li>
<li><a href="#questions-you-should-be-able-to-answer-after-this-assignment">Questions You Should Be Able to Answer After This Assignment</a></li>
</ul>
</div>
<h3 id="overview">Overview</h3>
<p>In this project, you will extend the Tartan Home system with new functionality
and test it for functional correctness, code quality, and quality attributes.
You will conduct this testing at multiple levels (e.g., unit, integration, and
system) primarily to verify functional correctness of existing and new code.
You may also need to modify your testing infrastructure from G1, as needed. The assignment
requires teams to extend the system to support a new smart door lock with
several features and test that functionality. G2 has two parts.</p>
<p>The learning goals of this group project are:</p>
<ul>
<li>Learn to to setup and manage a continuous testing strategy and supporting
  technologies.</li>
<li>Gain experience using different test case design techniques.</li>
<li>Select and integrate appropriate testing techniques throughout the
  engineering process, using appropriate technologies.</li>
<li>Select and assess various measures, including but not limited to code
  coverage, for the adequacy of a test suite.</li>
</ul>
<p>The following requirements must be satisfied to start this project:</p>
<ul>
<li>The team is familiar with collaborative development and code review
  features of Github (a quick recap will also be provided in the lab).</li>
<li>A development environment with Java, gradle and docker support,
  preferably together with a correctly configured IDE like Eclipse or
  IntelliJ that allows to execute unit tests and perform coverage analysis
  on Java projects.</li>
<li>Note that you must continue working on the same repository you created through GitHub classroom for group project 1. </li>
</ul>
<p>You will also likely need several additional tools to complete this assignment.
Please identify and describe these tools in your report.</p>
<h3 id="part-1-improve-test-suite">Part 1: Improve Test Suite</h3>
<p>In G1, you were still starting out with Tartan and did not know of all the techniques that can help you choose meaningful test cases and also assess the quality of your tests. Additionally, you only implemented one test per feature. </p>
<p>In the first part of this assignment, your task is to improve the quality of your test suite for the four rules you chose in G1 as follows:</p>
<ol>
<li>Use blackbox testing techniques to create better test cases and corresponding oracles (i.e., the concrete input values and expected output in your tests). You are advised to carefully read Tartan's specification and decide on whether there are additional scenarios you need to test for (e.g., now is time to think about whether the rules interact and if there are edge cases you need to think of). When selecting concrete oracles, some of your options include boundary value testing, random testing, or strong/weak equivalence class testing. You may think of other strategies too. Although you will work on your selected four rules for the blackbox testing, you need to think about all variables (old and new) of the evaluateState() function and how changing one particular state might affect your selected rules.</li>
<li>Use whitebox testing techniques to evaluate and improve the adequacy of your test suite. In this case, you are asked to write more tests that improve the coverage of your test suite to 80%.</li>
</ol>
<p>It does not need to be 80% of the entire system: you only need 80% coverage of the methods that implement your four rules. </p>
<p>Please refer to the code coverage tutorial posted on eClass and discussed in the lab to see how you can configure your coverage measurement tool to measure coverage only for your selected features. However, you must include <em>at least</em> all methods your blackbox tests interact with either directly or indirectly.</p>
<h4 id="acceptance-criteria-for-part-1">Acceptance criteria for Part 1</h4>
<p>The following criteria must be satisfied for Part 1 to be accepted as
complete. A description of the report you must submit is provided at the end.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Criteria</th>
<th style="text-align: left;">Grade</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Whitebox and blackbox test design and selection plans are completed and explained.</td>
<td style="text-align: left;">10</td>
</tr>
<tr>
<td style="text-align: left;">Automated measurement of coverage with each build is implemented</td>
<td style="text-align: left;">5</td>
</tr>
<tr>
<td style="text-align: left;">All tests pass.</td>
<td style="text-align: left;">10</td>
</tr>
<tr>
<td style="text-align: left;">Tests must achieve at least 80% statement and 80% branch coverage for the <em>features selected to test.</em></td>
<td style="text-align: left;">15</td>
</tr>
</tbody>
</table>
<h3 id="part-2-implementation-and-verification-of-a-smart-door-lock">Part 2: Implementation and Verification of a Smart Door Lock</h3>
<p>Tartan Inc. would like your team to implement the software logic for a new smart
door lock. The smart door lock hardware allows the door to be locked and
unlocked automatically using a passcode, and it will provide many "smart"
features that users can configure for additional security or convenience. Note that opening/closing the door is different from locking/unlocking a lock. The former refers to the physical state of the door while the latter refers to the state of the deadbolt on the door.
Specifically, the smart lock must support the following features that users
can enable or disable:</p>
<ul>
<li><em>Electronic Operation:</em> If a person requests a lock or unlock operation
  from an access panel, first check if that operation requires a
  passcode. If it does, read and check the passcode. If the passcode is refused, send a message to the access panel. Otherwise, perform the requested operation.</li>
<li><em>Keyless Entry:</em> When sensors detect a resident arriving on the
  property (e.g., proximity of a registered cell phone), automatically unlock the door.</li>
<li><em>Intruder Defense:</em> When sensors in the house detect the possible presence
  of an intruder, lock the door and send "possible intruder detected"
  messages to the access panels. Keep the door locked until the sensors
  provide an "all clear" signal, at which time "all clear" messages are
  sent to the access panels.</li>
<li><em>Night Lock:</em> Residents configure the time when night begins and ends. At
  night, automatically lock the door and always relock it if it becomes
  unlocked at any point during the night.</li>
</ul>
<p>An access panel is one of these: <br>
<img id="access-panel" alt="access panel" src="https://cmput402.github.io/group/adt-access-panel.jpg" style="width: 50%;"><br>
(Picture by Marco Albertini, https://securitycamcenter.com/how-to-reset-adt-alarm-system/).
For the access panel you can add the functionality to the frontend, since we don't have any physical access panels.
Make sure that your messages are shown on the frontend log of the application.
You can append the access panel messages to your log in your code and make sure it's showing up on the frontend.</p>
<p>Note that the above feature requirements may be ambiguous. In addition, features
may interact and the door lock should behave in a reasonable way, which can be
resolved with timers, priorities, or other mechanisms. For example, what
happens or should happen if an intruder is detected and a resident arrives at
the door? You should ask for clarification about requirements if needed and
explicitly document all assumptions you make about interactions.</p>
<p>Integrate the smart door lock and its features with the current system and test
it thoroughly. You can add additional sensors and actuators to the house, if
needed.</p>
<p><strong>While developing the new door lock features, you must follow a test-driven approach.</strong>
Use Pull Requests to integrate each new functionality and have another team member review your code. <strong>Each team member must perform a code review of
at least 1 PR.</strong></p>
<p>To make it easier for us to spot your test-driven development, you must make your commits
using a specific pattern that shows that you have worked using TDD. Make a
git commit after each of the following steps:</p>
<ul>
<li>Red: Write a test that fails. Make a commit with the word "RED" at the beginning of the commit message.</li>
<li>Green: Change the implementation so that the test succeeds. Make a commit with the word "GREEN".</li>
<li>Refactor: Rewrite the code. Make a commit with the word "REFACTOR". Your tests must still pass after this change.</li>
</ul>
<p>You must conduct unit testing on the new code and carefully measure coverage.
However, given that this is a new feature, you should also perform integration (i.e., tests that combine multiple classes/functionality) and system testing (i.e., end to end testing that treats the system as a black box). You must document the integration and system testing
procedures in your report. </p>
<h5 id="acceptance-criteria-for-part-2">Acceptance criteria for Part 2</h5>
<p>The following criteria must be satisfied for the assignment to be accepted as
complete.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Criteria</th>
<th style="text-align: left;">Grade</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Requirements for the smart door lock are documented. The documentation format is up to the team, but should be clear and complete and includes any assumptions the team made.</td>
<td style="text-align: left;">10</td>
</tr>
<tr>
<td style="text-align: left;">The software for the smart door lock successfully builds, runs, and implements stated requirements.</td>
<td style="text-align: left;">10</td>
</tr>
<tr>
<td style="text-align: left;">Integration and system testing strategy is implemented and described</td>
<td style="text-align: left;">10</td>
</tr>
<tr>
<td style="text-align: left;">Tests must achieve at least 80% statement and 80% branch coverage for <strong><em>new</em></strong> code.</td>
<td style="text-align: left;">15</td>
</tr>
<tr>
<td style="text-align: left;">The mutation score for the tests related to the new door lock functionality should be 90%</td>
<td style="text-align: left;">10</td>
</tr>
<tr>
<td style="text-align: left;">Test-driven development has been followed</td>
<td style="text-align: left;">5</td>
</tr>
<tr>
<td style="text-align: left;">New features underwent code review</td>
<td style="text-align: left;">5</td>
</tr>
</tbody>
</table>
<h3 id="report-for-parts-1-2">Report for Parts 1 &amp; 2</h3>
<p>Create a report as a single <strong>PDF</strong> file that describes your verification
activities, decisions, and results for both the existing functionality and the
new door lock (max. 4 pages of text, not including screenshots/tables etc). You must upload your report to eClass by the specified deadline. While marking, we will verify all acceptance criteria by checking both your report and code repository.
<strong>The final version of your code for all parts of this project must be in the master branch and tagged as <code>G2_Done</code> by the deadline.</strong></p>
<p>The following describe the required details of the report:</p>
<ul>
<li><strong>Part 1</strong>:<ul>
<li><strong>Chosen Rules</strong>: For completeness, restate the four rules you chose for part 1 (they should be the same as those from G1).</li>
<li><strong>Testing plan and test cases</strong>: Describe the
  process you used to design test cases and provide an overview of the tests
  you wrote. How were test cases designed? How were test values selected? Which
  testing techniques did you use (i.e. random testing, combinatorial testing,
  BVA, other)? Mention how much additional testing you needed to add in G2 when compared to G1. Finally, provide a pointer to the actual test classes/methods scripts in your repository.</li>
</ul>
</li>
<li><strong>Coverage</strong>: Provide a screenshot of your coverage report (you can focus only on the relevant parts of the system). While marking, we will look into the actual report ourselves and make sure you satisfy the coverage criteria.</li>
<li><strong>Part 2</strong>:<ul>
<li><strong>Clarified requirements for smart door lock</strong>:
  Describe all assumptions you made about the requirements of the smart door
  lock system and its features.</li>
</ul>
</li>
<li><strong>Software development processes</strong>: Briefly indicate
  the role of each group member in this process, describe how you planned and
  organized the design, development, and evaluation of the smart door lock.
  Include a description of how you coordinated implementation and
  testing.</li>
<li><strong>Overall testing strategy and implementation:</strong> . Indicate where your unit, integration, and system tests are implemented. Mention what you chose to test for integration testing as well as system testing. Which tools/frameworks/techniques did you use to implement your integration and system testing?</li>
<li><strong>Coverage and mutation score:</strong> Provide a screenshot of your coverage report (you can focus only on the relevant parts of the system). While marking, we will look into the actual report ourselves and make sure you satisfy the coverage criteria. Also, provide a screenshot of your mutation score report. Please mention 2-3 examples of initially live mutations (i.e., mutants that your test suite did not initially kill) and how you improved your test suite to kill these mutants.</li>
</ul>
<h3 id="grading-summary">Grading Summary</h3>
<p>In total, this project is worth 120 points with the following allocation:</p>
<ul>
<li>Part 1 (improving test suite): 40 points</li>
<li>Part 2 (implementation and verification): 65 points</li>
<li>Report: 10 points</li>
<li>Peer assessment: 5 points (Assigned individually)</li>
</ul>
<p>The report is graded based on its presentation, organization, and how clearly things are described. All the items described in the Report section above must appear in the report.</p>
<p>Each member must assess their team members' contributions on eClass. This is worth 5 points of the total assignment grade and is confidential (results go to the course staff). Note that if we find big discrepencies in contributions or if one team members is negatively rated by all other team members, then we will investigate and regrade team members as needed.</p>
<h3 id="questions-you-should-be-able-to-answer-after-this-assignment">Questions You Should Be Able to Answer After This Assignment</h3>
<ul>
<li>What is a unit?</li>
<li>How does TDD differ from standard types of testing?</li>
<li>What is an Oracle?</li>
<li>What might you need to change in the System Under Test in order to make good use of unit testing?</li>
<li>What makes black box testing different from white box testing?</li>
<li>Why might we want to use black box testing?</li>
<li>What is the purpose of unit-testing?</li>
<li>What are equivalence partitioning and boundary value analysis?</li>
<li>Why do we use TDD? What is its purpose?</li>
<li>Can we always have 100% code-coverage?</li>
<li>What are the different types of coverage criteria?</li>
<li>Does 100% coverage mean we are bug-free?</li>
<li>Does 100% MCDC coverage mean we are bug-free?</li>
<li>Can we prove that weâ€™re 100% bug-free?</li>
<li>In TDD, Why do we go for RED first?</li>
<li>How did you handle interactions in the requirements in part 2?</li>
<li>How did you test for intereactions?</li>
<li>Do the computed adequacy criteria give you confidence that your software is thoroughly tested and of adequate quality?</li>
<li>If you could pick your own goals for test adequacy measures, what would you aim for?</li>
<li>Which testing techniques were most effective for you and why?</li>
<li>Which techniques were less effective and why?</li>
<li>Did mutation testing help you find weaknesses in your test suite? Can you give an example?</li>
<li>If you had to conduct a similar project again, would you change any of your testing or planning strategies?</li>
<li>What were the challenges you faced and how did you solve them?</li>
</ul>
<p>Copyright 2021, 2022 Dr. Sarah Nadi. Copyright 2023, 2024 Dr. Hazel Campbell. All rights reserved.</p>
  <footer>
    <p>Published: <time datetime="2024-01-30T00:00:00-07:00">
      Tue, 30 Jan 2024 at 00:00 MST
    </time></p>
    <address>
      By           <a href="https://cmput402.github.io/author/hazel-victoria-campbell.html">Hazel Victoria Campbell</a>
          <a href="https://cmput402.github.io/author/sarah-nadi.html">Sarah Nadi</a>
    </address>
    <p>
        Category: <a href="https://cmput402.github.io/category/group.html">group</a>
    </p>
    <p>
        Tags:
            <a href="https://cmput402.github.io/tag/labs.html">labs</a>
            <a href="https://cmput402.github.io/tag/policy.html">policy</a>
            <a href="https://cmput402.github.io/tag/grading.html">grading</a>
    </p>
  </footer>
  </article>
        </main>
        <footer>
                <address>
                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>,
                which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                </address>
        </footer>
</body>
</html>